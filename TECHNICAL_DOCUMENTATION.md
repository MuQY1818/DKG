# DKG 项目技术详解

本文档提供对DKG项目的深度技术剖析，包括其核心架构、数据模型、关键算法及其数学实现。

---

## 1. 系统核心架构

本项目的核心是一个基于 `networkx.MultiDiGraph` 构建的动态知识图谱。其架构可分为以下几个层次：

- **数据层 (Data Layer)**: 位于最底层，由原始的CSV日志文件组成，例如 `skill_builder_data09-10.csv`。这些文件记录了最基本的学生-题目交互事件。
- **加载与预处理层 (Loading & Preprocessing Layer)**: 由 `data_loader.py` 负责。它读取原始CSV文件，进行数据清洗、格式转换、ID映射等预处理工作，并将其封装成统一格式的数据字典，供上层使用。
- **图谱构建与更新层 (Graph Construction & Update Layer)**: 这是系统的核心，由 `dkg_builder.py` 实现。它负责：
    1.  **静态构建**: 根据预处理后的数据，初始化整个知识图谱，创建包含学生、题目、技能的节点，以及它们之间的初始关系。
    2.  **动态更新**: 提供 `record_interaction` 等接口，在接收到新的学习行为后，实时更新图谱中的节点属性和关系权重，最核心的是更新学生对技能的"掌握度"。
- **API与应用层 (API & Application Layer)**: `DKGBuilder` 类同样暴露了一系列查询和推荐接口（如 `get_student_profile`, `recommend_next_problems`），供上层应用（例如 `run_api_example.py` 或未来的LLM集成应用）调用，以获取决策支持。

数据流向：
`CSV文件` -> `DataLoader` -> `结构化字典` -> `DKGBuilder` -> `动态知识图谱 (内存中)` -> `API调用` -> `应用结果 (画像, 推荐等)`

---

## 2. 核心数据模型详解

图谱采用 `networkx.MultiDiGraph`，因为它允许节点间存在多种不同类型的有向边，非常适合描述教育场景中的复杂关系。

### 2.1 节点 (Nodes)

图谱中主要有三种类型的节点：`student`, `problem`, `skill`。

#### a) 学生节点 (`student`)
- **唯一标识**: `student_{student_id}` (例如: `student_0`)
- **类型属性**: `type='student'`
- **核心属性**:
    - `student_id` (int): 学生的数字索引ID。
    - `learning_rate` (float): **[个性化参数]** 学生的学习效率，影响其掌握度更新速度。
    - `perseverance` (int): **[个性化参数]** 学生的毅力，影响其面对挫折的行为。
    - `curiosity` (float): **[个性化参数]** 学生的好奇心，影响其对新知识的探索倾向。

#### b) 题目节点 (`problem`)
- **唯一标识**: `problem_{problem_id}` (例如: `problem_15`)
- **类型属性**: `type='problem'`
- **核心属性**:
    - `problem_id` (int): 题目的数字索引ID。
    - `problem_type` (str): 题目类型（如 `objective`）。
    - `max_score` (float): 题目的满分。
    - `difficulty` (float): **[动态属性]** 题目的难度系数。
        - **初始值**: 0.5。
        - **更新机制**: *在当前版本中，该属性暂未实现动态更新。未来的版本可以基于所有学生的作答正确率进行调整。*
    - `discrimination` (float): **[静态属性]** 题目的区分度，衡量其区分高低水平学生的能力。

#### c) 技能节点 (`skill`)
- **唯一标识**: `skill_{skill_id}` (例如: `skill_25`)
- **类型属性**: `type='skill'`
- **核心属性**:
    - `skill_id` (int): 技能的数字索引ID。
    - `skill_name` (str): 技能的文本名称 (例如: "Addition and Subtraction of Integers")。
    - `difficulty_level` (float): 技能本身的难度。
    - `importance_weight` (float): 技能的重要性权重。

### 2.2 边 (Edges / Relations)

边代表了节点之间的关系，是图谱动态性的核心体现。

#### a) `solve` (学生 -> 题目)
- **描述**: 表示一个学生完成了一道题目。这是图谱中最基础、最频繁发生的事件。
- **类型属性**: `type='solve'`
- **核心属性**:
    - `correct` (int): 是否正确 (1或0)。
    - `score` (float): 本次作答的分数。
    - `attempts` (int): 尝试次数。
    - `time_taken` (int): 答题耗时（毫秒）。
    - `hints_used` (int): 使用提示的数量。

#### b) `require` (题目 -> 技能)
- **描述**: 表示一道题目考察了一个或多个技能。这个关系通常是静态的，在图谱构建之初就根据Q矩阵（Problem-Skill Matrix）确定。
- **类型属性**: `type='require'`
- **核心属性**:
    - `weight` (float): 该技能在题目中的重要性权重。

#### c) `master` (学生 -> 技能)
- **描述**: 这是整个学生模型的核心。它表示一个学生对某个技能的掌握程度。这条边的属性是动态更新的。
- **类型属性**: `type='master'`
- **核心属性**:
    - `mastery_score` (float): **[核心动态指标]** 对该技能的当前掌握水平。
        - **计算方法**: 详见 3.2.2 节。
    - `history` (list): 记录了与该技能相关的历次交互正误（`[1, 0, 1]`）。
    - `last_updated` (timestamp): 最近一次更新的时间。

#### d) `prerequisite` (技能 -> 技能)
- **描述**: 表示技能之间的前置依赖关系（例如，必须先学"一元一次方程"才能学"一元二次方程"）。这是通过分析学生学习序列的共现关系推断出来的。
- **类型属性**: `type='prerequisite'`
- **核心属性**:
    - `confidence` (float): 该依赖关系的置信度。
        - **计算方法**: 基于学生学习路径中共现技能对的条件概率。

#### e) `similar` (技能 -> 技能)
- **描述**: 表示两个技能在考察内容上具有相似性。这是通过计算技能在题目上的向量表示（基于Q矩阵）的余弦相似度得出的。
- **类型属性**: `type='similar'`
- **核心属性**:
    - `similarity` (float): 相似度分数。
        - **计算方法**: 详见 3.1.2 节。

---
*下一部分将深入讲解关键的动态流程：图谱构建、交互更新和问题推荐。*

## 3. 关键算法与流程详解

### 3.1 静态图谱构建 (`build_from_data`)

此过程在首次加载数据时执行，建立图谱的骨架。

#### 3.1.1 初始掌握度计算
在创建 `master` 关系时，学生的初始掌握度 $M_{initial}$ 是根据其在相关历史题目上的平均表现计算的：
$$
M_{initial}(s, k) = \frac{\sum_{p \in P_k} C(s, p)}{|P_k|}
$$
其中，$s$ 是学生，$k$ 是技能，$P_k$ 是学生 $s$ 已作答的、考察技能 $k$ 的题目集合，$C(s, p)$ 是学生在题目 $p$ 上的作答结果（1为正确，0为错误）。如果 $|P_k|=0$，则初始值默认为0.5。

#### 3.1.2 技能相似度计算
技能间的 `similar` 关系是通过计算其向量表示的余弦相似度得出的。首先，根据Q矩阵（problem-skill matrix）为每个技能 $k$ 构建一个向量 $\vec{v_k}$，该向量的维度等于总题目数，如果题目 $p$ 考察技能 $k$，则向量的第 $p$ 个分量为1，否则为0。
技能 $k_i$ 和 $k_j$ 的相似度 $\text{sim}(k_i, k_j)$ 计算如下：
$$
\text{sim}(k_i, k_j) = \frac{\vec{v_{k_i}} \cdot \vec{v_{k_j}}}{||\vec{v_{k_i}}|| \cdot ||\vec{v_{k_j}}||}
$$

#### 3.1.3 技能前置关系推断 (`_infer_skill_prerequisites`)
`prerequisite` 关系是通过分析**题目-技能矩阵 (Q-matrix)** 的结构来自动发现的，而非分析学生学习的时间顺序。其核心思想是，如果技能B的出现总是伴随着技能A的出现，但反之不成立，则A很可能是B的前置技能。

1.  **计算技能共现矩阵**: 系统首先计算一个技能-技能共现矩阵，其中每个元素 $(i, j)$ 代表同时需要技能 $i$ 和技能 $j$ 的题目数量。
    
2.  **计算条件概率**: 对于任意技能对 $(A, B)$，系统会计算两个方向的条件概率：
    -   $P(A|B)$: 考察技能B的题目中，同时也考察了技能A的概率。
    -   $P(B|A)$: 考察技能A的题目中，同时也考察了技能B的概率。
    
3.  **建立关系**: 如果 $P(A|B)$ 远大于 $P(B|A)$，并且 $P(A|B)$ 本身超过一个高置信度阈值（例如0.7），系统则判断A是B的前置技能，并建立一条从A指向B的 `prerequisite` 边。该边的 `confidence` 属性值即为 $P(A|B)$。

### 3.2 动态交互更新 (`record_interaction`)
当系统记录一次新的学习交互时，它会触发一系列的动态更新，以实时反映学生认知状态的变化。这个过程不仅仅是更新单个数据点，而是模拟了一个复杂的认知演化过程。

该函数的核心流程如下：
1.  **更新解题关系 (`solve`)**: 在学生和题目节点之间创建或更新 `solve` 关系，记录本次交互的详细信息，如得分、尝试次数、时间戳等。

2.  **更新直接相关的技能掌握度 (`_update_skill_mastery`)**:
    - 系统会找出该题目所考察的所有直接关联技能。
    - 对于每一个技能，系统会根据交互结果（如是否正确）来调整学生对该技能的 `mastery_level`。其核心更新逻辑如下：
      $$
      \Delta M_{base} = \begin{cases} 0.1 \times \text{learning\_rate} & \text{if correct} \\ -0.02 & \text{if incorrect} \end{cases}
      $$
      $$
      M_{new} = \text{clip}(M_{current} + \Delta M_{base} + \text{bonus}_{epiphany}, 0, 1)
      $$
      其中 `learning_rate` 是学生的个性化参数，实现了差异化建模。代码中还预留了`is_epiphany`（顿悟）接口，允许在特定条件下实现掌握度的非线性大幅提升。

3.  **知识强化传播 (`_propagate_reinforcement`)**: 这是动态更新中最精妙的一环。
    - 当一个技能的掌握度因本次交互而提升后，系统会启动一个递归的强化传播过程。
    - 该过程会将本次掌握度的**总变化量**（$\Delta M_{total} = \Delta M_{base} + \text{bonus}_{epiphany}$），按照一个预设的衰减因子（`decay_factor`），反向传播给该技能的所有**直接前置技能**。
      $$
      \Delta M_{propagated} = \Delta M_{total} \times \text{decay\_factor}
      $$
      $$
      M_{new\_prereq} = \text{clip}(M_{current\_prereq} + \Delta M_{propagated}, 0, 1)
      $$
    - 这个传播会持续递归下去，直到没有更底层的先修技能为止。
    - **该机制的意义**: 它完美地模拟了教育学中的"知识巩固"现象——即**练习和应用高级知识，本身就是对相关基础知识的有效复习和强化**。

### 3.3 推荐与诊断

#### 3.3.1 问题推荐 (`recommend_next_problems`)
系统的推荐模块旨在为学生规划出一条高效且人性化的学习路径。其核心算法的设计并非简单的随机选择或难度排序，而是深度融合了教育心理学中的**"最近发展区" (Zone of Proximal Development, ZPD) 理论**。

该理论指出，最有效的学习发生在学生现有能力水平之上、但又尚未达到独立解决问题能力的区域。系统通过以下步骤来实现这一理论：

1.  **识别薄弱技能**: 首先，系统会找出学生当前`mastery_level`低于特定阈值（如0.7）的技能，作为潜在的学习目标。
2.  **计算题目适合度 (`_calculate_problem_suitability`)**: 对于每个薄弱技能下的候选题目，系统会计算一个"适合度"分数。这个分数的核心是寻找题目难度与学生能力的最佳匹配点：
    - **理想难度匹配**: 系统认为最理想的题目难度 `difficulty` 应该略高于学生对该技能的当前掌握度 `mastery_level`。这个"略高于"的区域，就是学生的"最近发展区"。
    - **避免无效练习**: 如果学生已经做对过某道题，其适合度将被大幅降低，以避免无效的重复。
3.  **生成推荐列表**: 系统汇总所有候选题目的适合度分数，并按从高到低排序，最终生成一个既能巩固薄弱知识点、又具有一定挑战性的个性化推荐列表。

#### 3.3.2 面向LLM的提示生成 (`generate_llm_prompt`)
此功能是连接DKG与大语言模型(LLM)的桥梁，旨在利用DKG的结构化知识来赋能LLM，生成高质量的学习路径规划。它并非直接输出学习计划，而是精心构建一个信息丰富的、结构化的**Prompt**。

这个Prompt通过以下方式，将DKG的分析结果"翻译"为LLM能够理解和利用的上下文：
1.  **设定角色与任务**: 明确指示LLM扮演"AI教育规划专家"的角色。
2.  **提供学生画像**:
    - **知识强项与弱项**: 提取学生当前掌握度最高和最低的技能，让LLM对学生的现有知识水平有清晰的认知。
    - **学习目标**: 明确告知LLM学生希望达成的学习目标。
3.  **注入核心规则**:
    - **前置关系约束**: 将从图谱中抽取的、与学习目标相关的**所有`prerequisite`关系**作为硬性约束提供给LLM，确保其生成的学习路径在逻辑上是正确、可行的。

通过这种方式，DKG将最关键的结构化知识（学生状态、知识点依赖关系）注入到LLM的推理过程中，极大地提升了LLM生成个性化、有效学习计划的准确性和质量。

## 4. 模块功能拆解

除了核心的 `dkg_builder.py`，`dkg_mvp` 目录下还包含以下辅助模块：

-   **`data_loader.py`**:
    -   **功能**: 数据的入口。负责从不同的数据源（如Assistments, Math2015等）加载原始数据。
    -   **职责**: 执行数据清洗、缺失值处理、ID到索引的映射、数据结构统一化等预处理任务，为 `DKGBuilder` 提供格式标准的输入。

-   **`api_tests.py`**:
    -   **功能**: 单元测试和API验证。
    -   **职责**: 包含一系列针对 `DKGBuilder` 各个公开API的测试用例，确保图谱的构建、更新、查询、推荐等功能符合预期，是保证代码质量和稳定性的关键。

-   **`simulation.py`**:
    -   **功能**: 学习过程模拟器。
    -   **职责**: 提供一个可以模拟学生学习行为的引擎。可以用于在没有真实数据流的情况下，测试DKG的动态更新和推荐逻辑是否闭环，也可用于进行算法效果的对比实验。

-   **`visualization.py` & `interactive_visualization.py`**:
    -   **功能**: 可视化工具。
    -   **职责**: `visualization.py` 提供静态的图谱可视化方法（如将整个图或其子图绘制成图片）。`interactive_visualization.py` 则利用 `pyvis` 等库，生成可交互的HTML文件，允许用户在浏览器中缩放、拖动、点击节点来探索图谱结构。

-   **`convert_data.py` & `examples.py`**:
    -   **功能**: 工具和示例脚本。
    -   **职责**: `convert_data.py` 可能包含一些一次性的数据格式转换脚本。`examples.py` 则可能提供了一些更具体的、针对特定功能点的API使用范例。

-   **`requirements.txt`**:
    -   **功能**: 项目依赖列表。
    -   **职责**: 列出了运行本项目所需的所有Python第三方库及其版本，方便一键安装。

## 4. 附录

### 4.1 数据源兼容性
`DKGBuilder`在设计上考虑了对不同格式教育数据的兼容性。在图谱构建的`_create_solve_relations`阶段，系统能够自动识别并处理以下三种主流数据类型：
- **日志型数据**: 每一行都是一次完整的学习交互记录（如ASSISTments数据集）。
- **二值矩阵**: （学生 x 题目）的0/1矩阵，代表是否答对（如FrcSub数据集）。
- **连续分数矩阵**: （学生 x 题目）的浮点数矩阵，代表得分比例（如Math1/Math2数据集）。

这种灵活性使得该工具可以方便地应用于更广泛的教育场景中。 