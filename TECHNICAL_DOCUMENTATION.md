# 技术文档：基于 ORCDF 的认知诊断引擎

## 1. 引言

本项目旨在构建一个高性能、高精度的学生认知诊断后端服务。为了克服传统认知诊断模型和标准图神经网络（GNN）在处理教育数据时遇到的挑战，我们采用了 **ORCDF (Oversmoothing-Resistant Cognitive Diagnosis Framework)** 这一先进的图神经网络框架。

ORCDF 的核心优势在于其能够有效抵抗 GNN 中普遍存在的“过平滑”现象，并能更精细地利用学生的作答响应信号（答对或答错），从而生成更具区分度的学生和练习表征，最终提升预测的准确性。

本文档将详细阐述系统的核心架构、数据处理流程、模型训练细节以及API服务的工作原理。

## 2. 模型架构 (ORCDF)

ORCDF 模型是我们系统的核心。它在 `dkg_mvp/orcdf/model.py` 中实现，其关键组成部分如下：

### 2.1 响应图 (Response Graph, ResG)

与传统GNN不同，ORCDF构建了一个包含学生、练习和知识点三类节点的异构图。更重要的是，它将学生的“正确”与“错误”响应直接编码为图的结构，形成了两个独立的子图：

- **正确响应子图 (`A`)**: 一条边 `(u, i)` 存在，当且仅当学生 `u` 正确回答了练习 `i`。
- **错误响应子图 (`IA`)**: 一条边 `(u, i)` 存在，当且仅当学生 `u` 错误回答了练习 `i`。

这种设计使得图卷积网络可以从两种不同性质的交互中学习信息。

### 2.2 响应感知图卷积 (Response-aware Graph Convolution, RGC)

RGC 是 ORCDF 的核心卷积层。它在上述两个子图上并行地、独立地进行信息传播：

- **正确通道**: 在正确子图 `A` 上进行图卷积，聚合“成功解决问题”的上下文信息。
- **错误通道**: 在错误子图 `IA` 上进行图卷积，聚合“在问题上遇到困难”的上下文信息。

每一层 RGC 都会产生来自两个通道的嵌入，然后模型将这些信息进行聚合，以更新学生和练习的表示。通过堆叠多层 RGC 并对各层结果进行平均池化，模型可以从多个维度和深度捕捉学生的知识状态。

### 2.3 一致性正则化 (Consistency Regularization)

为了处理学生在答题过程中可能出现的“猜测”（猜对）和“失误”（知识点掌握但答错）这两种噪声，ORCDF引入了一种新颖的一致性正则化损失。

在每个训练周期中，系统会：
1.  随机“翻转”一小部分（由 `flip_ratio` 控制）响应边的类型（正确→错误，错误→正确），生成一个“噪声图”。
2.  模型同时在原始图和噪声图上进行前向传播，得到两组嵌入表示。
3.  通过一个正则化损失项（`reg_loss`），迫使模型从原始图和噪声图中学习到的嵌入表示保持一致。

这种机制增强了模型对噪声数据的鲁棒性，使其能够学习到更本质的学生掌握水平，而不是被偶然的猜测或失误所干扰。

## 3. 数据处理流程

数据处理由 `dkg_mvp/data_loader.py` 中的 `DataLoader` 类负责。其核心方法 `load_orcdf_data` 执行以下步骤：

1.  **加载原始数据**: 从 `dataset/clear_dataset/` 目录加载学生交互、练习和技能的 CSV 文件。
2.  **创建ID映射**: 为学生、练习和技能创建从0开始的连续整数索引，同时保留原始ID以供API查询。
3.  **构建图矩阵**:
    - 根据交互记录，生成 `a_matrix` (正确) 和 `ia_matrix` (错误) 两个Numpy矩阵。
    - 根据练习-技能关系，生成 `q_matrix`。
4.  **格式化输出**: 返回一个包含所有实体数量、ID映射和图矩阵的字典，供训练脚本和API服务器使用。

## 4. 训练流程

模型训练由 `dkg_mvp/train_orcdf.py` 脚本执行，可以通过 `python -m dkg_mvp.train_orcdf` 命令启动。

其主要流程如下：
1.  **加载数据**: 调用 `DataLoader` 获取完整的图数据。
2.  **数据分割**: 将交互记录分割为训练集和验证集。
3.  **模型初始化**: 实例化 `ORCDF` 模型、Adam优化器和BCE损失函数。
4.  **训练循环**: 对每个 Epoch：
    - 调用 `create_flipped_graphs` 函数，根据 `flip_ratio` 创建当前周期的噪声图。
    - 在训练集上分批次进行训练：
        a. 在 **原始图** 和 **噪声图** 上分别执行前向传播。
        b. 计算 **联合损失**：`Loss = BCELoss(预测) + λ * ConsistencyLoss(嵌入1, 嵌入2)`。
        c. 执行反向传播和参数更新。
    - 在验证集上评估模型的 AUC 和准确率。
5.  **模型保存**: 如果当前模型在验证集上的 AUC 超过了历史最佳，则将其权重保存到 `models/` 目录下的 `.pt` 文件中。

## 5. API 服务

API 服务由 `api_server.py` 提供，基于 FastAPI 构建。

### 启动过程

服务器启动时，会执行以下关键操作：
1.  **加载数据**: 调用 `DataLoader` 加载完整的图矩阵和ID映射，并将其存储在 `app.state` 中。
2.  **加载模型**: 实例化 `ORCDF` 模型，并从 `models/` 目录加载训练好的 `.pt` 权重文件。
3.  **设置模式**: 将模型设置为评估模式 (`model.eval()`)。

### 核心端点

- `POST /api/predict`:
    1.  接收一个包含原始 `student_id` 和 `problem_id` 的JSON列表。
    2.  使用 `app.state` 中存储的ID映射，将原始ID转换为模型所需的内部索引。
    3.  将索引转换为 `torch.Tensor`。
    4.  调用 `model()` 函数，传入ID张量和完整的图矩阵（`a_matrix`, `ia_matrix`, `q_matrix`）进行预测。
    5.  将预测出的概率与原始ID一起格式化为JSON响应返回。 