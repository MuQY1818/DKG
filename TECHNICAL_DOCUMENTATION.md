# DKG 项目技术详解

本文档提供对DKG项目的深度技术剖析，包括其核心架构、数据模型、关键算法及其数学实现。

---

## 1. 系统核心架构

本项目的核心是一个基于 `networkx.MultiDiGraph` 构建的动态知识图谱。其架构可分为以下几个层次：

- **数据层 (Data Layer)**: 位于最底层，由原始的CSV日志文件组成，例如 `skill_builder_data09-10.csv`。这些文件记录了最基本的学生-题目交互事件。
- **加载与预处理层 (Loading & Preprocessing Layer)**: 由 `data_loader.py` 负责。它读取原始CSV文件，进行数据清洗、格式转换、ID映射等预处理工作，并将其封装成统一格式的数据字典，供上层使用。
- **图谱构建与更新层 (Graph Construction & Update Layer)**: 这是系统的核心，由 `dkg_builder.py` 实现。它负责：
    1.  **静态构建**: 根据预处理后的数据，初始化整个知识图谱，创建包含学生、题目、技能的节点，以及它们之间的初始关系。
    2.  **动态更新**: 提供 `record_interaction` 等接口，在接收到新的学习行为后，实时更新图谱中的节点属性和关系权重，最核心的是更新学生对技能的"掌握度"。
- **API与应用层 (API & Application Layer)**: `DKGBuilder` 类同样暴露了一系列查询和推荐接口（如 `get_student_profile`, `recommend_next_problems`），供上层应用（例如 `api_server.py` 或未来的LLM集成应用）调用，以获取决策支持。

数据流向：
`CSV文件` -> `DataLoader` -> `结构化字典` -> `DKGBuilder` -> `动态知识图谱 (内存中)` -> `API调用` -> `应用结果 (画像, 推荐等)`

---

## 2. 核心数据模型详解

图谱采用 `networkx.MultiDiGraph`，因为它允许节点间存在多种不同类型的有向边，非常适合描述教育场景中的复杂关系。

### 2.1 节点 (Nodes)

图谱中主要有三种类型的节点：`student`, `problem`, `skill`。

#### a) 学生节点 (`student`)
- **唯一标识**: `student_{student_id}` (例如: `student_73963`)
- **类型属性**: `type='student'`
- **核心属性**:
    - `student_id` (int): 学生的**原始ID**。
    - `learning_rate` (float): **[个性化参数]** 学生的学习效率，影响其掌握度更新速度。
    - `perseverance` (int): **[个性化参数]** 学生的毅力，影响其面对挫折的行为。
    - `curiosity` (float): **[个性化参数]** 学生的好奇心，影响其对新知识的探索倾向。

#### b) 题目节点 (`problem`)
- **唯一标识**: `problem_{problem_id}` (例如: `problem_76429`)
- **类型属性**: `type='problem'`
- **核心属性**:
    - `problem_id` (int): 题目的**原始ID**。
    - `problem_type` (str): 题目类型（如 `objective`）。
    - `max_score` (float): 题目的满分。
    - `difficulty` (float): **[动态属性]** 题目的难度系数。
        - **初始值**: 0.5。
        - **更新机制**: *在当前版本中，该属性暂未实现动态更新。未来的版本可以基于所有学生的作答正确率进行调整。*
    - `discrimination` (float): **[静态属性]** 题目的区分度，衡量其区分高低水平学生的能力。

#### c) 技能节点 (`skill`)
- **唯一标识**: `skill_{skill_id}` (例如: `skill_297`)
- **类型属性**: `type='skill'`
- **核心属性**:
    - `skill_id` (int): 技能的**原始ID**。
    - `skill_name` (str): 技能的文本名称 (例如: "Addition and Subtraction of Integers")。
    - `difficulty_level` (float): 技能本身的难度。
    - `importance_weight` (float): 技能的重要性权重。

### 2.2 边 (Edges / Relations)

边代表了节点之间的关系，是图谱动态性的核心体现。

#### a) `solve` (学生 -> 题目)
- **描述**: 表示一个学生完成了一道题目。这是图谱中最基础、最频繁发生的事件。
- **类型属性**: `type='solve'`
- **核心属性**:
    - `correct` (int): 是否正确 (1或0)。
    - `score` (float): 本次作答的分数。
    - `attempts` (int): 尝试次数。
    - `time_taken` (int): 答题耗时（毫秒）。
    - `hints_used` (int): 使用提示的数量。

#### b) `require` (题目 -> 技能)
- **描述**: 表示一道题目考察了一个或多个技能。这个关系通常是静态的，在图谱构建之初就根据Q矩阵（Problem-Skill Matrix）确定。
- **类型属性**: `type='require'`
- **核心属性**:
    - `weight` (float): 该技能在题目中的重要性权重。

#### c) `master` (学生 -> 技能)
- **描述**: 这是整个学生模型的核心。它表示一个学生对某个技能的掌握程度。这条边的属性是动态更新的。
- **类型属性**: `type='master'`
- **核心属性**:
    - `mastery_level` (float): **[核心动态指标]** 对该技能的当前掌握水平。
        - **计算方法**: 详见 3.2.2 节。
    - `confidence` (float): 对当前掌握水平的置信度。
    - `last_updated` (timestamp): 最近一次更新的时间。

#### d) `prerequisite` (技能 -> 技能)
- **描述**: 表示技能之间的前置依赖关系（例如，必须先学"一元一次方程"才能学"一元二次方程"）。这是通过分析学生学习序列的共现关系推断出来的。
- **类型属性**: `type='prerequisite'`
- **核心属性**:
    - `confidence` (float): 该依赖关系的置信度。
        - **计算方法**: 基于学生学习路径中共现技能对的条件概率。

#### e) `similar` (技能 -> 技能)
- **描述**: 表示两个技能在考察内容上具有相似性。这是通过计算技能在题目上的向量表示（基于Q矩阵）的余弦相似度得出的。
- **类型属性**: `type='similar'`
- **核心属性**:
    - `similarity` (float): 相似度分数。
        - **计算方法**: 详见 3.1.2 节。

---
*下一部分将深入讲解关键的动态流程：图谱构建、交互更新和问题推荐。*

## 3. 关键算法与流程详解

### 3.1 静态图谱构建 (`build_from_data`)

此过程在首次加载数据时执行，建立图谱的骨架。

#### 3.1.1 初始掌握度计算
在创建 `master` 关系时，学生的初始掌握度 $M_{initial}$ 是根据其在相关历史题目上的平均表现计算的：
$$
M_{initial}(s, k) = \frac{\sum_{p \in P_k} C(s, p)}{|P_k|}
$$
其中，$s$ 是学生，$k$ 是技能，$P_k$ 是学生 $s$ 已作答的、考察技能 $k$ 的题目集合，$C(s, p)$ 是学生在题目 $p$ 上的作答结果（1为正确，0为错误）。如果 $|P_k|=0$，则初始值默认为0.5。

#### 3.1.2 技能相似度计算
技能间的 `similar` 关系是通过计算其向量表示的余弦相似度得出的。首先，根据Q矩阵（problem-skill matrix）为每个技能 $k$ 构建一个向量 $\vec{v_k}$，该向量的维度等于总题目数，如果题目 $p$ 考察技能 $k$，则向量的第 $p$ 个分量为1，否则为0。
技能 $k_i$ 和 $k_j$ 的相似度 $\text{sim}(k_i, k_j)$ 计算如下：
$$
\text{sim}(k_i, k_j) = \frac{\vec{v_{k_i}} \cdot \vec{v_{k_j}}}{||\vec{v_{k_i}}|| \cdot ||\vec{v_{k_j}}||}
$$

#### 3.1.3 技能前置关系推断 (`_infer_skill_prerequisites`)
`prerequisite` 关系是通过分析**题目-技能矩阵 (Q-matrix)** 的结构来自动发现的，而非分析学生学习的时间顺序。其核心思想是，如果技能B的出现总是伴随着技能A的出现，但反之不成立，则A很可能是B的前置技能。

1.  **计算技能共现矩阵**: 系统首先计算一个技能-技能共现矩阵，其中每个元素 $(i, j)$ 代表同时需要技能 $i$ 和技能 $j$ 的题目数量。
    
2.  **计算条件概率**: 对于任意技能对 $(A, B)$，系统会计算两个方向的条件概率：
    -   $P(A|B)$: 考察技能B的题目中，同时也考察了技能A的概率。
    -   $P(B|A)$: 考察技能A的题目中，同时也考察了技能B的概率。
    
3.  **建立关系**: 如果 $P(A|B)$ 远大于 $P(B|A)$，并且 $P(A|B)$ 本身超过一个高置信度阈值（例如0.7），系统则判断A是B的前置技能，并建立一条从A指向B的 `prerequisite` 边。该边的 `confidence` 属性值即为 $P(A|B)$。

### 3.2 动态交互更新 (`record_interaction`)
当系统记录一次新的学习交互时，它会触发一系列的动态更新，以实时反映学生认知状态的变化。这个过程不仅仅是更新单个数据点，而是模拟了一个复杂的认知演化过程。

该函数的核心流程如下：
1.  **更新解题关系 (`solve`)**: 在学生和题目节点之间创建或更新 `solve` 关系，记录本次交互的详细信息，如得分、尝试次数、时间戳等。

2.  **更新直接相关的技能掌握度 (`_update_skill_mastery`)**:
    - 系统会找出该题目所考察的所有直接关联技能。
    - 对于每一个技能，系统会根据交互结果（如是否正确）来调整学生对该技能的 `mastery_level`。其核心更新逻辑如下：
      $$
      \Delta M_{base} = \begin{cases} 0.1 \times \text{learning\_rate} & \text{if correct} \\ -0.02 & \text{if incorrect} \end{cases}
      $$
      $$
      M_{new} = \text{clip}(M_{current} + \Delta M_{base} + \text{bonus}_{epiphany}, 0, 1)
      $$
      其中 `learning_rate` 是学生的个性化参数，实现了差异化建模。代码中还预留了`is_epiphany`（顿悟）接口，允许在特定条件下实现掌握度的非线性大幅提升。

3.  **知识强化传播 (`_propagate_reinforcement`)**: 这是动态更新中最精妙的一环。
    - 当一个技能的掌握度因本次交互而提升后，系统会启动一个递归的强化传播过程。
    - 该过程会将本次掌握度的**总变化量**（$\Delta M_{total} = \Delta M_{base} + \text{bonus}_{epiphany}$），按照一个预设的衰减因子（`decay_factor`），反向传播给该技能的所有**直接前置技能**。
      $$
      \Delta M_{propagated} = \Delta M_{total} \times \text{decay\_factor}
      $$
      $$
      M_{new\_prereq} = \text{clip}(M_{current\_prereq} + \Delta M_{propagated}, 0, 1)
      $$
    - 这个传播会持续递归下去，直到没有更底层的先修技能为止。
    - **该机制的意义**: 它完美地模拟了教育学中的"知识巩固"现象——即**练习和应用高级知识，本身就是对相关基础知识的有效复习和强化**。

### 3.3 推荐与诊断

#### 3.3.1 问题推荐 (`recommend_next_problems`)
系统的推荐模块旨在为学生规划出一条高效且人性化的学习路径。其核心算法的设计并非简单的随机选择或难度排序，而是深度融合了教育心理学中的**"最近发展区" (Zone of Proximal Development, ZPD) 理论**。

该理论指出，最有效的学习发生在学生现有能力水平之上、但又尚未达到独立解决问题能力的区域。系统通过以下步骤来实现这一理论：

1.  **识别薄弱技能**: 首先，系统会找出学生当前`mastery_level`低于特定阈值（如0.7）的技能，作为潜在的学习目标。
2.  **计算题目适合度 (`_calculate_problem_suitability`)**: 对于每个薄弱技能下的候选题目，系统会计算一个"适合度"分数。这个分数的核心是寻找题目难度与学生能力的最佳匹配点。其计算分为两步：
    - **A. 难度适合度**: 首先，基于学生对该技能的掌握度（$M$）和题目的难度（$D$），计算基础的难度适合度（$S_{diff}$）。理想的题目难度被设定为略高于学生当前水平（$M+0.1$）。
      $$
      S_{diff} = \max(0, 1 - 2 \times |D - (M + 0.1)|)
      $$
    - **B. 挑战因子**: 接着，为了避免题目过易或过难，引入一个挑战因子（$F_{challenge}$）进行调节。
      $$
      F_{challenge} = \begin{cases} 0.5 & \text{if } D < M - 0.2 \text{ (过易)} \\ 0.3 & \text{if } D > M + 0.3 \text{ (过难)} \\ 1.0 & \text{otherwise (难度适中)} \end{cases}
      $$
    - **C. 最终适合度**: 最终的适合度由两者相乘得到。
      $$
      S_{total} = S_{diff} \times F_{challenge}
      $$
    - **避免无效练习**: 如果学生已经做对过某道题，其适合度将被直接设为一个较低的值（如0.3），以避免无效的重复。
3.  **生成推荐列表**: 系统汇总所有候选题目的适合度分数，并按从高到低排序，最终生成一个既能巩固薄弱知识点、又具有一定挑战性的个性化推荐列表。

#### 3.3.2 面向LLM的提示生成 (`generate_llm_prompt`)
此功能是连接DKG与大语言模型(LLM)的桥梁，旨在利用DKG的结构化知识来赋能LLM，生成高质量的学习路径规划。它并非直接输出学习计划，而是精心构建一个信息丰富的、结构化的**Prompt**。

这个Prompt通过以下方式，将DKG的分析结果"翻译"为LLM能够理解和利用的上下文：
1.  **设定角色与任务**: 明确指示LLM扮演"AI教育规划专家"的角色。
2.  **提供学生画像**:
    - **知识强项与弱项**: 提取学生当前掌握度最高和最低的技能，让LLM对学生的现有知识水平有清晰的认知。
    - **学习目标**: 明确告知LLM学生希望达成的学习目标。
3.  **注入核心规则**:
    - **前置关系约束**: 将从图谱中抽取的、与学习目标相关的**所有`prerequisite`关系**作为硬性约束提供给LLM，确保其生成的学习路径在逻辑上是正确、可行的。

通过这种方式，DKG将最关键的结构化知识（学生状态、知识点依赖关系）注入到LLM的推理过程中，极大地提升了LLM生成个性化、有效学习计划的准确性和质量。

<details>
<summary>点击查看Prompt生成示例</summary>

```
# **角色：**
你是一位顶级的AI教育规划专家，精通认知科学和教学设计。

# **任务：**
基于以下提供的学生知识状态和知识图谱规则，为该学生设计一条个性化的、循序渐进的学习路径，以帮助他掌握目标技能。

---

# **学生知识画像 (Student Profile):**

## **1. 基本信息:**
- **学生ID:** 3

## **2. 知识强项 (已掌握的技能):**
- **一元一次方程**: 掌握度 0.85
- **代数基础**: 掌握度 0.92

## **3. 知识弱项 (最需要提升的技能):**
- **分解因式**: 掌握度 0.33
- **函数初步**: 掌握度 0.41

---

# **学习目标与规则 (Goal and Constraints):**

## **1. 学习目标:**
学生希望系统地学习并掌握以下技能：
- **一元二次方程**

## **2. 必须遵守的规则 (知识结构):**
学习路径的规划必须严格遵守以下知识点之间的先修关系。一个技能必须在其所有的先修技能都被掌握后才能开始学习。
- **'代数基础'** 是 **'一元一次方程'** 的先修技能。
- **'一元一次方程'** 是 **'一元二次方程'** 的先修技能。
- **'分解因式'** 是 **'一元二次方程'** 的先修技能。

---

# **输出要求 (Output Format):**

请提供一个清晰的、分步骤的学习计划。每个步骤应包含：
1.  **学习的技能名称**。
2.  **推荐学习该技能的理由** (例如：因为它是掌握目标技能XXX的必要前提，或者是学生当前的知识薄弱点)。
3.  **学习顺序**：请确保整个计划的顺序严格遵循先修关系，并从学生最需要弥补的知识点开始。

请开始生成学习计划：
```

</details>

## 4. 模块功能拆解

*   **`dkg_mvp/data_loader.py`**:
    *   **职责**: 数据加载与预处理。
    *   **核心函数**: `load_assistments_log_data`, `load_math2015_data`。
    *   **输出**: 标准化的数据字典，包含`interactions` (DataFrame), `q_matrix` (numpy array), `skill_names`等。

*   **`dkg_mvp/dkg_builder.py`**:
    *   **职责**: DKG的构建、更新、查询和推荐。是整个系统的核心引擎。
    *   **核心类**: `DKGBuilder`。
    *   **核心方法**:
        *   `build_from_data`: 从数据字典静态构建初始图谱。
        *   `record_interaction`: 接收新的交互，动态更新图谱。
        *   `get_student_profile`: 获取学生画像。
        *   `recommend_next_problems`: 根据ZPD理论推荐问题。
        *   `generate_llm_prompt`: 生成用于驱动大语言模型的提示。

*   **`dkg_mvp/gnn_trainer.py`**:
    *   **职责**: 训练图神经网络模型，用于性能预测。
    *   **核心流程**: 将DKG转换为PyG的`HeteroData`格式，定义GNN Encoder和Link Predictor Decoder，进行端到端的训练与评估。
    *   **定位**: 作为项目的下一代技术探索，验证数据驱动方法的可行性。

*   **`run_api_example.py`**:
    *   **职责**: 作为API的使用示例，展示如何调用`DKGBuilder`的核心功能来模拟一个完整的"诊断-学习-再诊断"的流程。

## 5. 未来工作与前瞻：基于图神经网络（GNN）的性能预测

当前DKG模型依赖于显式定义的规则（如ZPD、知识巩固传播）进行更新和推荐。虽然这提供了很好的可解释性，但模型捕捉复杂、高阶特征的能力有限。引入图神经网络（GNN）旨在通过端到端的学习，自动从图结构中学习学生、题目和技能的向量表征（Embeddings），从而实现更精确的学生表现预测。

我们已经通过 `dkg_mvp/gnn_trainer.py` 脚本完成了一个原型验证。该实现基于 **PyTorch Geometric (PyG)** 框架，探索了利用GNN进行链路预测的可行性。

### 5.1 核心流程

1.  **异构图转换**: 将 `dkg_builder` 生成的 `networkx` 图谱转换为 PyG 的 `HeteroData` 对象。该对象能清晰地表示不同类型的节点（`student`, `problem`, `skill`）和边（`solve`, `require`, 以及它们的反向边）。

2.  **模型架构**:
    *   **编码器 (Encoder)**: 采用一个两层的 `SAGEConv` 模型。`SAGEConv` 是一种强大的图卷积算子，能够聚合邻居节点的信息来生成目标节点的表征。编码器的作用是将图中的每个节点映射到一个低维、稠密的向量空间中。
    *   **解码器 (Decoder)**: 一个简单的多层感知机（MLP），如代码中定义的 `LinkPredictor`。它的任务是接收一对（学生，题目）节点的表征向量，并预测它们之间是否存在 "solve" 链接，实际上是预测学生能否正确解决该问题。

3.  **训练与评估**:
    *   **任务**: 将问题定义为一个**链路预测 (Link Prediction)** 任务。我们遮盖（mask）掉一部分 `(student, 'solve', problem)` 的边，让模型去预测这些被遮盖的边是否存在。
    *   **数据划分**: 将 `solve` 交互边按照 8:1:1 的比例划分为训练集、验证集和测试集。
    *   **损失函数**: 使用 `BCEWithLogitsLoss`，适用于二分类任务（预测交互的 `correct` 标签，即成功或失败）。
    *   **评估指标**: 使用 `AUC` (Area Under Curve) 和 `F1-Score` 来评估模型在验证集和测试集上的预测性能。

### 5.2 成果与展望

*   **初步结果**: 实验证明，该GNN模型在测试集上取得了 `AUC: 0.707` 和 `F1-Score: 0.808` 的基准性能，验证了此方法的有效性。
*   **应用价值**: 训练好的GNN模型产出的**节点表征 (Node Embeddings)** 具有极高的价值。这些表征可以替代或补充DKG中手工设计的特征（如 `mastery_score`），用于：
    1.  **更精准的推荐**: 基于学生和问题的向量相似度进行推荐。
    2.  **学生聚类**: 发现具有相似知识结构或学习行为的学生群体。
    3.  **知识结构分析**: 分析技能和题目的表征，发现隐含的知识结构关系。
*   **演进路径**: 这为项目从一个**可解释的规则引擎**演进为一个**数据驱动的智能预测与推荐系统**提供了清晰的技术路径。

## 4. 附录

### 4.1 数据源兼容性
`DKGBuilder`在设计上考虑了对不同格式教育数据的兼容性。在图谱构建的`_create_solve_relations`阶段，系统能够自动识别并处理以下三种主流数据类型：
- **日志型数据**: 每一行都是一次完整的学习交互记录（如ASSISTments数据集）。
- **二值矩阵**: （学生 x 题目）的0/1矩阵，代表是否答对（如FrcSub数据集）。
- **连续分数矩阵**: （学生 x 题目）的浮点数矩阵，代表得分比例（如Math1/Math2数据集）。

这种灵活性使得该工具可以方便地应用于更广泛的教育场景中。 